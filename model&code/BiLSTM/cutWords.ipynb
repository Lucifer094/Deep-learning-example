{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USing jieba to cut all answer sentences to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_answer1_path = '../data/student1ch.xlsx'\n",
    "reference_answer_path = '../data/reference_answers_extended_ch.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWords(str):  \n",
    "    reg = \"[^A-Za-z\\u4e00-\\u9fa5]\"\n",
    "    words = ' '.join(jieba.cut(str)).split(' ')  \n",
    "    new = ''\n",
    "    number = 0\n",
    "    for word in words:\n",
    "        word = re.sub(reg, '', word)\n",
    "        if word is not '':\n",
    "            number = number + 1\n",
    "            new = new + word + ' '\n",
    "        else:\n",
    "            continue\n",
    "    if number != 0:\n",
    "        return new, number\n",
    "    else:\n",
    "        return new[:-1], number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/d4/21c1h0bd5z92rhvl5smhfvw40000gn/T/jieba.cache\n",
      "Loading model cost 1.219 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "student_answer1_df = pd.read_excel(student_answer1_path)\n",
    "new_colum1 = []\n",
    "new_colum2 = []\n",
    "for i in student_answer1_df.index:\n",
    "    string, number = buildWords(str(student_answer1_df.iloc[i][1]))\n",
    "    new_colum1.append(string)\n",
    "    new_colum2.append(number)\n",
    "student_answer1_df.insert(2,'answer_cut',new_colum1)\n",
    "student_answer1_df.insert(3,'words_num',new_colum2)\n",
    "student_answer1_df = student_answer1_df.rename(columns={'格线':'score'})\n",
    "student_answer1_df.to_csv('../data/student1ch_expand.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answer_df = pd.read_excel(reference_answer_path)\n",
    "new_colum1 = []\n",
    "new_colum2 = []\n",
    "for i in reference_answer_df.index:\n",
    "    string, number = buildWords(str(reference_answer_df.iloc[i][1]))\n",
    "    new_colum1.append(string)\n",
    "    new_colum2.append(number)\n",
    "reference_answer_df.insert(2,'answer_cut',new_colum1)\n",
    "reference_answer_df.insert(3,'words_num',new_colum2)\n",
    "reference_answer_df = reference_answer_df.rename(columns={'格线':'score','refans_text':'refence_text'})\n",
    "reference_answer_df.to_csv('../data/reference_answers_extended_ch.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make all the setences vectorization and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the data and store them in DataFrame.\n",
    "answer_all = pd.read_csv('../data/student1ch_expand.csv', encoding='utf-8')\n",
    "question_all = pd.read_excel(\"../data/questions_ch.xlsx\")\n",
    "reference_all = pd.read_csv(\"../data/reference_answers_extended_ch.csv\", encoding='utf-8')\n",
    "\n",
    "# Extract the students` answers, the question`s describition and references of question 36.\n",
    "answer_ext = answer_all[answer_all.Question_ID==36]\n",
    "question_ext = question_all[question_all.Question_ID==36]\n",
    "reference_ext = reference_all[reference_all.Question_ID==36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_y = le.fit_transform(answer_ext.score).reshape(-1,1)\n",
    "ohe = OneHotEncoder()\n",
    "data_y = ohe.fit_transform(data_y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2000\n",
    "max_len = 40\n",
    "tok = Tokenizer(num_words=max_words)  ## The max word number is 5000\n",
    "tok.fit_on_texts(answer_ext.answer_cut.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_seq = tok.texts_to_sequences(answer_ext.answer_cut.astype(str))\n",
    "data_seq_mat = sequence.pad_sequences(data_seq,maxlen=max_len)\n",
    "data_seq_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_seq = tok.texts_to_sequences(reference_ext.answer_cut.astype(str))\n",
    "reference_seq_mat = sequence.pad_sequences(reference_seq,maxlen=max_len)\n",
    "reference_seq_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq_mat = data_seq_mat[0:180]\n",
    "train_y = data_y[0:180]\n",
    "\n",
    "val_seq_mat = data_seq_mat[180:210]\n",
    "val_y = data_y[180:210]\n",
    "\n",
    "test_seq_mat = data_seq_mat[210:]\n",
    "test_y = data_y[210:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_train_matrix = reference_seq_mat\n",
    "for i in range(train_seq_mat.shape[0]-1):\n",
    "    reference_train_matrix = np.row_stack((reference_train_matrix,reference_seq_mat))\n",
    "pd.DataFrame(reference_train_matrix).to_csv('reference_train.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = train_seq_mat\n",
    "for i in range(reference_seq_mat.shape[0]-1):\n",
    "    train_matrix = np.row_stack((train_matrix,train_seq_mat))\n",
    "pd.DataFrame(train_matrix).to_csv('train_matrix.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_new = train_y\n",
    "for i in range(reference_seq_mat.shape[0]-1):\n",
    "    train_y_new = np.row_stack((train_y_new,train_y))\n",
    "pd.DataFrame(train_y_new).to_csv('train_y_new.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
