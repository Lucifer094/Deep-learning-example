{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "uuid": "9ee78aec-2c85-4a8d-9b23-085193746a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Read the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "25e80624-c3ad-499c-a60d-9277c55fad93"
   },
   "outputs": [],
   "source": [
    "trainWordsDf = pd.read_csv('conv_train.csv')\n",
    "testWordsDf = pd.read_csv('conv_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Using Tokenizer result to vectorize the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the vectorization result same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "uuid": "0773549a-537d-49c3-b8fa-792c2511f655"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "max_len = 300\n",
    "with open('tok.pickle', 'rb') as handle:\n",
    "    tok = pickle.load(handle)\n",
    "train_seq = tok.texts_to_sequences(trainWordsDf.Cut)\n",
    "test_seq = tok.texts_to_sequences(testWordsDf.Cut)\n",
    "train_seq_mat = sequence.pad_sequences(train_seq,maxlen=max_len)\n",
    "test_seq_mat = sequence.pad_sequences(test_seq,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "uuid": "a15bf334-31e5-4e8b-8342-c414024eca5e"
   },
   "outputs": [],
   "source": [
    "train_y = trainWordsDf.Flag.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Define a model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "uuid": "b4d53ec2-1e5e-4cbc-9d33-460d1f26967c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 300, 128)          1280128   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,576,321\n",
      "Trainable params: 1,576,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "\n",
    "# inputs = Input(name='inputs',shape=[max_len])\n",
    "# ## Embedding(size of word table,size of batch,length of every news)\n",
    "# layer = Embedding(max_words+1,128,input_length=max_len)(inputs)\n",
    "# layer = LSTM(128)(layer)\n",
    "# layer = Dense(128,activation=\"relu\",name=\"FC1\")(layer)\n",
    "# layer = Dropout(0.5)(layer)\n",
    "# layer = Dense(1,activation=\"sigmoid\",name=\"FC2\")(layer)\n",
    "# model = Model(inputs=inputs,outputs=layer)\n",
    "# model.summary()\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "inputs = Input(name='inputs',shape=[max_len])\n",
    "## Embedding(size of word table,size of batch,length of every news)\n",
    "layer = Embedding(max_words+1,128,input_length=max_len)(inputs)\n",
    "layer = Bidirectional(LSTM(128))(layer)\n",
    "layer = Dense(128,activation=\"relu\",name=\"FC1\")(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(1,activation=\"sigmoid\",name=\"FC2\")(layer)\n",
    "model = Model(inputs=inputs,outputs=layer)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "uuid": "28edf5d7-b238-41c8-8ccc-5050d0170477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135656 samples\n",
      "Epoch 1/20\n",
      "135656/135656 [==============================] - 56s 410us/sample - loss: 0.0441 - accuracy: 0.9906\n",
      "Epoch 2/20\n",
      "135656/135656 [==============================] - 53s 389us/sample - loss: 0.0317 - accuracy: 0.9913\n",
      "Epoch 3/20\n",
      "135656/135656 [==============================] - 54s 396us/sample - loss: 0.0280 - accuracy: 0.9919\n",
      "Epoch 4/20\n",
      "135656/135656 [==============================] - 54s 398us/sample - loss: 0.0232 - accuracy: 0.9931\n",
      "Epoch 5/20\n",
      "135656/135656 [==============================] - 54s 396us/sample - loss: 0.0180 - accuracy: 0.9945\n",
      "Epoch 6/20\n",
      "135656/135656 [==============================] - 53s 394us/sample - loss: 0.0141 - accuracy: 0.9960\n",
      "Epoch 7/20\n",
      "135656/135656 [==============================] - 54s 401us/sample - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 8/20\n",
      "135656/135656 [==============================] - 54s 399us/sample - loss: 0.0090 - accuracy: 0.9976\n",
      "Epoch 9/20\n",
      "135656/135656 [==============================] - 53s 392us/sample - loss: 0.0079 - accuracy: 0.9978\n",
      "Epoch 10/20\n",
      "135656/135656 [==============================] - 53s 390us/sample - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 11/20\n",
      "135656/135656 [==============================] - 54s 397us/sample - loss: 0.0048 - accuracy: 0.9987\n",
      "Epoch 12/20\n",
      "135656/135656 [==============================] - 53s 392us/sample - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 13/20\n",
      "135656/135656 [==============================] - 54s 396us/sample - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 14/20\n",
      "135656/135656 [==============================] - 53s 388us/sample - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 15/20\n",
      "135656/135656 [==============================] - 53s 394us/sample - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 16/20\n",
      "135656/135656 [==============================] - 52s 385us/sample - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 17/20\n",
      "135656/135656 [==============================] - 53s 392us/sample - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 18/20\n",
      "135656/135656 [==============================] - 53s 390us/sample - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 19/20\n",
      "135656/135656 [==============================] - 53s 389us/sample - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 20/20\n",
      "135656/135656 [==============================] - 53s 387us/sample - loss: 8.2003e-04 - accuracy: 0.9998\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_seq_mat,train_y,batch_size=256,epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Store the train history, model, perdect the test data and store the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('history.txt','w')\n",
    "f.write(str(model_fit.history))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "uuid": "226ed986-c3b3-4b48-b181-ffc459c8435c"
   },
   "outputs": [],
   "source": [
    "## Model`s save and download.\n",
    "from tensorflow.keras.models import load_model\n",
    "# Save\n",
    "model.save('my_model.h5')  \n",
    "del model  # deletes the existing model\n",
    "# Downlod\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "uuid": "e060b92b-7dc5-46c9-8f98-1a8a6fc74a00"
   },
   "outputs": [],
   "source": [
    "predict = model.predict(test_seq_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "uuid": "0d6dd880-cda1-44bf-a454-8e5980ef0f25"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.053516e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.285665e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.003254e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.452652e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.076798e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50064</th>\n",
       "      <td>50065</td>\n",
       "      <td>2.853299e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50065</th>\n",
       "      <td>50066</td>\n",
       "      <td>1.148497e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50066</th>\n",
       "      <td>50067</td>\n",
       "      <td>1.152184e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50067</th>\n",
       "      <td>50068</td>\n",
       "      <td>9.443950e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50068</th>\n",
       "      <td>50069</td>\n",
       "      <td>1.410631e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50069 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SessionId   Probability\n",
       "0              1  7.053516e-10\n",
       "1              2  8.285665e-11\n",
       "2              3  3.003254e-09\n",
       "3              4  2.452652e-05\n",
       "4              5  5.076798e-09\n",
       "...          ...           ...\n",
       "50064      50065  2.853299e-04\n",
       "50065      50066  1.148497e-03\n",
       "50066      50067  1.152184e-05\n",
       "50067      50068  9.443950e-08\n",
       "50068      50069  1.410631e-09\n",
       "\n",
       "[50069 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDf = pd.DataFrame(range(1,(len(testWordsDf.index)+1)),columns=['SessionId'])\n",
    "resultDf['Probability'] = predict\n",
    "resultDf.to_csv('result.csv', index=0)\n",
    "resultDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
